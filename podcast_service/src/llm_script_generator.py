#!/usr/bin/env python3
"""
LLM æ’­å®¢è„šæœ¬ç”Ÿæˆå™¨
ä½¿ç”¨ OpenAI GPT-4-mini ä»ä»»æ„ topic/content ç”Ÿæˆæ’­å®¢è„šæœ¬
æ”¯æŒå¤šè¯­è¨€ã€å¤šè®²è¯äººã€å¤šç§æ ¼å¼

åŠŸèƒ½ï¼š
1. ä»è‡ªç”±å½¢å¼çš„å†…å®¹ç”Ÿæˆç»“æ„åŒ–çš„æ’­å®¢è„šæœ¬
2. æ”¯æŒä¸åŒçš„è®²è¯äººæ•°é‡å’Œè§’è‰²
3. ç”Ÿæˆ SSML æ ¼å¼çš„è¯­éŸ³å‹å¥½æ–‡æœ¬
4. æ”¯æŒè‡ªå®šä¹‰è¯­è°ƒã€é£æ ¼ã€æ—¶é•¿ç­‰
"""

import os
import json
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path

import openai
from openai import OpenAI

# ============================================================================
# æ—¥å¿—é…ç½®
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# æšä¸¾å®šä¹‰
# ============================================================================

class PodcastTone(Enum):
    """æ’­å®¢è¯­è°ƒ"""
    PROFESSIONAL = "professional"       # ä¸“ä¸šä¸¥è‚ƒ
    CASUAL = "casual"                   # éšæ„è½»æ¾
    EDUCATIONAL = "educational"         # æ•™è‚²æ€§
    ENTERTAINING = "entertaining"       # å¨±ä¹æ€§
    INVESTIGATIVE = "investigative"     # è°ƒæŸ¥æ€§
    STORYTELLING = "storytelling"       # æ•…äº‹å™è¿°
    HUMOROUS = "humorous"               # å¹½é»˜
    DEBATE = "debate"                   # è¾©è®º

class DialogueStyle(Enum):
    """å¯¹è¯é£æ ¼"""
    MONOLOGUE = "monologue"             # å•äººç‹¬ç™½
    INTERVIEW = "interview"             # é‡‡è®¿å¯¹è¯
    DEBATE = "debate"                   # è¾©è®ºè®¨è®º
    CONVERSATION = "conversation"       # éšæ„å¯¹è¯
    NARRATION = "narration"             # æ—ç™½è§£è¯´
    PANEL = "panel"                     # ä¸“å®¶è®ºå›

# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

@dataclass
class ScriptSegment:
    """è„šæœ¬æ®µè½"""
    speaker_id: str
    speaker_name: str
    text: str              # åŸå§‹æ–‡æœ¬
    ssml_text: str         # SSML æ ¼å¼
    duration_seconds: float
    segment_type: str      # "opening", "main", "closing" ç­‰
    notes: Optional[str] = None

@dataclass
class PodcastScript:
    """å®Œæ•´æ’­å®¢è„šæœ¬"""
    topic: str
    title: str
    description: str
    language: str
    tone: PodcastTone
    dialogue_style: DialogueStyle
    num_speakers: int
    estimated_duration_seconds: float
    segments: List[ScriptSegment] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    token_usage: Optional[Dict[str, int]] = None  # {prompt_tokens, completion_tokens, total_tokens}
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        result = {
            'topic': self.topic,
            'title': self.title,
            'description': self.description,
            'language': self.language,
            'tone': self.tone.value,
            'dialogue_style': self.dialogue_style.value,
            'num_speakers': self.num_speakers,
            'estimated_duration_seconds': self.estimated_duration_seconds,
            'segments': [
                {
                    'speaker_id': seg.speaker_id,
                    'speaker_name': seg.speaker_name,
                    'text': seg.text,
                    'ssml_text': seg.ssml_text,
                    'duration_seconds': seg.duration_seconds,
                    'segment_type': seg.segment_type,
                    'notes': seg.notes
                }
                for seg in self.segments
            ],
            'metadata': self.metadata
        }
        if self.token_usage:
            result['token_usage'] = self.token_usage
        return result

# ============================================================================
# LLM è„šæœ¬ç”Ÿæˆå™¨
# ============================================================================

class LLMScriptGenerator:
    """ä½¿ç”¨ OpenAI LLM ç”Ÿæˆæ’­å®¢è„šæœ¬"""
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "gpt-4o-mini"
    ):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            api_key: OpenAI API key (é»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–)
            model: ä½¿ç”¨çš„æ¨¡å‹ (é»˜è®¤ gpt-4o-mini - è½»é‡çº§ä¸”é«˜æ•ˆ)
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        self.model = model
        self.client = OpenAI(api_key=self.api_key)
        
        logger.info(f"âœ… LLM è„šæœ¬ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ (model={model})")

    def _is_gpt5_model(self) -> bool:
        return self.model.lower().startswith("gpt-5")

    def _chat_completions_create_by_model(
        self,
        messages: List[Dict[str, str]],
        max_output_tokens: int,
        temperature: float = 0.7,
        top_p: float = 0.95,
    ):
        """
        æŒ‰æ¨¡å‹åˆ†å¼€é€»è¾‘ï¼š
        - gpt-5 ç³»åˆ—ï¼šåªä½¿ç”¨ max_completion_tokensï¼Œä¸ä¼  temperature/top_p
        - é gpt-5ï¼šä½¿ç”¨ max_tokens + temperature/top_p
        """
        if self._is_gpt5_model():
            return self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_completion_tokens=max_output_tokens,
            )
        return self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            top_p=top_p,
            max_tokens=max_output_tokens,
        )
    
    def generate_script(
        self,
        topic: str,
        num_speakers: int = 2,
        duration_minutes: int = 5,
        language: str = "en-US",
        tone: PodcastTone = PodcastTone.PROFESSIONAL,
        dialogue_style: DialogueStyle = DialogueStyle.CONVERSATION,
        speaker_names: Optional[List[str]] = None,
        template_speaker_ids: Optional[List[str]] = None,
        additional_context: Optional[str] = None,
        custom_instructions: Optional[str] = None
    ) -> PodcastScript:
        """
        ä» topic ç”Ÿæˆæ’­å®¢è„šæœ¬
        
        Args:
            topic: æ’­å®¢ä¸»é¢˜/å†…å®¹
            num_speakers: è®²è¯äººæ•°é‡
            duration_minutes: ç›®æ ‡æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            language: è¯­è¨€ä»£ç  (en-US, zh-CN, ko-KR ç­‰)
            tone: è¯­è°ƒé£æ ¼
            dialogue_style: å¯¹è¯é£æ ¼
            speaker_names: è®²è¯äººåå­—åˆ—è¡¨
            additional_context: é¢å¤–èƒŒæ™¯ä¿¡æ¯
            custom_instructions: è‡ªå®šä¹‰ç”ŸæˆæŒ‡ä»¤
        
        Returns:
            PodcastScript å¯¹è±¡
        """
        
        logger.info(f"ğŸ™ï¸ å¼€å§‹ç”Ÿæˆæ’­å®¢è„šæœ¬...")
        logger.info(f"   Topic: {topic[:60]}...")
        logger.info(f"   Speakers: {num_speakers}")
        logger.info(f"   Duration: {duration_minutes} min")
        logger.info(f"   Language: {language}")
        logger.info(f"   Tone: {tone.value}")
        logger.info(f"   Style: {dialogue_style.value}")
        
        # IMPORTANT:
        # If caller does not provide `speaker_names` (None) we should NOT
        # auto-fill them here. Previously we auto-generated placeholder
        # names which then forced the LLM to reuse generic names. Keep
        # `speaker_names` as None so the LLM can generate realistic human
        # names based on role/gender when instructed.
        
        # æ„å»ºæç¤ºè¯
        system_prompt = self._build_system_prompt(
            tone, dialogue_style, language
        )
        
        user_prompt = self._build_user_prompt(
            topic=topic,
            num_speakers=num_speakers,
            duration_minutes=duration_minutes,
            language=language,
            speaker_names=speaker_names,
            additional_context=additional_context,
            custom_instructions=custom_instructions
        )
        
        logger.info(f"\nğŸ“ è°ƒç”¨ LLM ç”Ÿæˆè„šæœ¬...")
        
        # è°ƒç”¨ OpenAI APIï¼ˆæŒ‰æ¨¡å‹åˆ†æ”¯ï¼‰
        try:
            response = self._chat_completions_create_by_model(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                max_output_tokens=8000,
                temperature=0.7,
                top_p=0.95,
            )
            
            # Extract response content
            script_json = response.choices[0].message.content
            logger.info(f"âœ… LLM å“åº”æ”¶åˆ°")

            # æå– token ä½¿ç”¨ç»Ÿè®¡
            usage_dict = None
            if hasattr(response, 'usage') and response.usage:
                try:
                    # OpenAI SDK è¿”å›çš„ usage æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—å…¸
                    usage_obj = response.usage
                    usage_dict = {
                        'prompt_tokens': usage_obj.prompt_tokens,
                        'completion_tokens': usage_obj.completion_tokens,
                        'total_tokens': usage_obj.total_tokens
                    }
                    logger.info(f"ğŸ“Š LLM Token ä½¿ç”¨ç»Ÿè®¡:")
                    logger.info(f"   Prompt tokens: {usage_dict['prompt_tokens']}")
                    logger.info(f"   Completion tokens: {usage_dict['completion_tokens']}")
                    logger.info(f"   Total tokens: {usage_dict['total_tokens']}")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ— æ³•è§£æ token ä½¿ç”¨ç»Ÿè®¡: {e}")
            
            # è§£æ JSON å“åº”
            script_data = json.loads(script_json)

            # æ„å»º PodcastScript å¯¹è±¡
            script = self._parse_script_response(
                script_data,
                topic=topic,
                tone=tone,
                dialogue_style=dialogue_style,
                language=language,
                num_speakers=num_speakers,
                template_speaker_ids=template_speaker_ids
            )

            # å°† usage ä¿¡æ¯æ”¾å…¥è„šæœ¬ metadataï¼ˆä»¥ä¾¿ä¿å­˜/å®¡è®¡ï¼‰
            if usage_dict:
                script.metadata['usage'] = usage_dict
            
            logger.info(f"âœ… è„šæœ¬åˆæ¬¡ç”Ÿæˆå®Œæˆ")
            logger.info(f"   æ®µè½æ•°: {len(script.segments)}")
            logger.info(f"   é¢„è®¡æ—¶é•¿: {script.estimated_duration_seconds:.1f} ç§’")
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡æ—¶é•¿ï¼Œå¦‚æœä¸å¤Ÿåˆ™è¿›è¡Œæ‰©å±•
            target_duration = duration_minutes * 60
            expansion_attempts = 0
            max_expansions = 3
            
            while script.estimated_duration_seconds < target_duration * 0.85 and expansion_attempts < max_expansions:
                expansion_attempts += 1
                logger.info(f"\nğŸ”„ å†…å®¹é•¿åº¦ä¸è¶³ï¼Œè¿›è¡Œç¬¬ {expansion_attempts} æ¬¡æ‰©å±•...")
                logger.info(f"   å½“å‰æ—¶é•¿: {script.estimated_duration_seconds:.1f}s")
                logger.info(f"   ç›®æ ‡æ—¶é•¿: {target_duration}s")
                
                # è°ƒç”¨æ‰©å±•æ–¹æ³•
                expanded_script = self._expand_script(
                    script, target_duration, language, tone, dialogue_style,
                    template_speaker_ids=template_speaker_ids
                )
                
                # ç´¯ç§¯tokenä½¿ç”¨ç»Ÿè®¡
                if hasattr(expanded_script, 'metadata') and 'usage' in expanded_script.metadata:
                    expansion_usage = expanded_script.metadata['usage']
                    if usage_dict:
                        # ç´¯åŠ tokenç»Ÿè®¡
                        usage_dict['prompt_tokens'] += expansion_usage.get('prompt_tokens', 0)
                        usage_dict['completion_tokens'] += expansion_usage.get('completion_tokens', 0)
                        usage_dict['total_tokens'] += expansion_usage.get('total_tokens', 0)
                        script.metadata['usage'] = usage_dict
                    
                    logger.info(f"ğŸ“Š æ‰©å±•è½®æ¬¡Tokenç»Ÿè®¡:")
                    logger.info(f"   +Prompt tokens: {expansion_usage.get('prompt_tokens', 0)}")
                    logger.info(f"   +Completion tokens: {expansion_usage.get('completion_tokens', 0)}")
                    logger.info(f"   ç´¯è®¡Total tokens: {usage_dict.get('total_tokens', 0)}")
                
                script = expanded_script
                logger.info(f"âœ… æ‰©å±•å®Œæˆï¼Œæ–°æ—¶é•¿: {script.estimated_duration_seconds:.1f}s")
            
            if expansion_attempts > 0:
                logger.info(f"\nâœ… ç»è¿‡ {expansion_attempts} æ¬¡æ‰©å±•åç”Ÿæˆå®Œæˆ")
            logger.info(f"   æœ€ç»ˆæ®µè½æ•°: {len(script.segments)}")
            logger.info(f"   æœ€ç»ˆé¢„è®¡æ—¶é•¿: {script.estimated_duration_seconds:.1f} ç§’")
            
            # å°†ç´¯ç§¯çš„ token ä½¿ç”¨ç»Ÿè®¡è®¾ç½®åˆ°è„šæœ¬å¯¹è±¡
            if usage_dict:
                script.token_usage = usage_dict
                logger.info(f"ğŸ“Š æœ€ç»ˆç´¯ç§¯ Token ç»Ÿè®¡: {usage_dict['total_tokens']} tokens")
            
            return script
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON è§£æå¤±è´¥: {e}")
            logger.error(f"åŸå§‹å“åº”: {script_json}")
            raise ValueError("LLM è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼")
        
        except Exception as e:
            logger.error(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
            raise

    def _build_system_prompt(
        self,
        tone: PodcastTone,
        dialogue_style: DialogueStyle,
        language: str
    ) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        
        tone_desc = {
            PodcastTone.PROFESSIONAL: "ä¿æŒä¸“ä¸šã€ä¸¥è‚ƒçš„è¯­æ°”",
            PodcastTone.CASUAL: "è½»æ¾ã€éšæ„çš„å¯¹è¯é£æ ¼",
            PodcastTone.EDUCATIONAL: "æ•™è‚²æ€§ã€è®²è§£æ€§çš„å†…å®¹",
            PodcastTone.ENTERTAINING: "å¨±ä¹æ€§å¼ºã€å¸å¼•å¬ä¼—",
            PodcastTone.INVESTIGATIVE: "æ·±åº¦è°ƒæŸ¥ã€æ‰¹åˆ¤æ€§æ€ç»´",
            PodcastTone.STORYTELLING: "æ•…äº‹å™è¿°é£æ ¼ã€å¼•äººå…¥èƒœ",
            PodcastTone.HUMOROUS: "å¹½é»˜ã€è½»æ¾ã€èƒ½é€—ç¬‘",
            PodcastTone.DEBATE: "è¾©è®ºæ€§ã€è§‚ç‚¹ç¢°æ’",
        }
        
        style_desc = {
            DialogueStyle.MONOLOGUE: "å•äººç‹¬ç™½ã€è®²è€…ä¸»å¯¼",
            DialogueStyle.INTERVIEW: "é‡‡è®¿å½¢å¼ã€é—®ç­”äº’åŠ¨",
            DialogueStyle.DEBATE: "è¾©è®ºå½¢å¼ã€è§‚ç‚¹å¯¹ç«‹",
            DialogueStyle.CONVERSATION: "éšæ„å¯¹è¯ã€è‡ªç„¶æµç•…",
            DialogueStyle.NARRATION: "æ—ç™½è§£è¯´ã€ä¿¡æ¯ä¼ è¾¾",
            DialogueStyle.PANEL: "ä¸“å®¶è®ºå›ã€å¤šäººè®¨è®º",
        }
        
        lang_indicator = {
            "en-US": "è‹±æ–‡",
            "en-GB": "è‹±æ–‡",
            "zh-CN": "ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰",
            "zh-TW": "ä¸­æ–‡ï¼ˆç¹ä½“ï¼‰",
            "ko-KR": "éŸ©æ–‡",
            "ja-JP": "æ—¥æ–‡",
        }.get(language, "è‹±æ–‡")
        
        return f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ’­å®¢è„šæœ¬ç¼–å‰§å’Œå†…å®¹ç­–åˆ’ä¸“å®¶ï¼Œä¸“é—¨åˆ›ä½œæ·±å…¥ã€è¯¦ç»†ã€é«˜è´¨é‡çš„é•¿ç¯‡æ’­å®¢å†…å®¹ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ç”Ÿæˆé«˜è´¨é‡çš„ã€å†…å®¹ä¸°å¯Œçš„æ’­å®¢è„šæœ¬ï¼Œæ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š

1. **è¯­è¨€**: {lang_indicator}
2. **è¯­è°ƒ**: {tone_desc.get(tone, "è‡ªç„¶æµç•…")}
3. **é£æ ¼**: {style_desc.get(dialogue_style, "è‡ªç„¶å¯¹è¯")}

**æ ¸å¿ƒåŸåˆ™ - å†…å®¹é•¿åº¦å’Œæ·±åº¦**:
- ä½ å¿…é¡»ç”Ÿæˆå®Œæ•´ã€è¯¦ç»†çš„å†…å®¹ï¼Œä¸è¦å› ä¸ºæ‹…å¿ƒç¯‡å¹…è€Œç¼©çŸ­è®¨è®º
- æ¯ä¸ªä¸»é¢˜éƒ½è¦æ·±å…¥å±•å¼€ï¼ŒåŒ…å«å…·ä½“ä¾‹å­ã€æ•°æ®ã€æ•…äº‹å’Œæ¡ˆä¾‹
- è®²è¯äººä¹‹é—´è¦æœ‰å……åˆ†çš„äº’åŠ¨å’Œæ¥å›å¯¹è¯
- å®å¯å†…å®¹ä¸°å¯Œè€Œç•¥é•¿ï¼Œä¹Ÿä¸è¦å†…å®¹å•è–„è€Œè¿‡çŸ­
- ç”¨æˆ·æŒ‡å®šçš„ç›®æ ‡æ—¶é•¿æ˜¯æœ€ä½è¦æ±‚ï¼Œä½ åº”è¯¥åŠªåŠ›è¾¾åˆ°æˆ–è¶…è¿‡è¿™ä¸ªæ—¶é•¿

ç”Ÿæˆè„šæœ¬æ—¶ï¼Œè¯·éµå¾ªä»¥ä¸‹æŒ‡å—ï¼š
- å†…å®¹çœŸå®ã€å¯ä¿¡ï¼Œé¿å…è™šæ„äº‹å®
- æ¯ä¸ªæ®µè½åº”è¯¥æœ‰æ˜ç¡®çš„è®²è¯äºº
- å¯¹è¯åº”è¯¥è‡ªç„¶ã€æœ‰èŠ‚å¥ï¼Œé€‚åˆå£å¤´è¡¨è¾¾ï¼Œä½†ä¹Ÿè¦æœ‰è¶³å¤Ÿçš„ä¿¡æ¯å¯†åº¦
- åŒ…å«è‡ªç„¶çš„åœé¡¿ã€è¯­æ°”å˜åŒ–ç­‰æŒ‡ç¤º
- è¿”å›æ ¼å¼å¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSON

å…³é”®è¦æ±‚ï¼š
- å¿…é¡»è¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼
- æ¯ä¸ªè®²è¯äººçš„æ–‡æœ¬åº”è¯¥è‡ªç„¶ã€æœ‰ä¸ªæ€§ã€ä¿¡æ¯ä¸°å¯Œ
- å†…å®¹åº”è¯¥æ·±å…¥ã€è¯¦ç»†ã€æœ‰ä»·å€¼ï¼Œå……åˆ†æ»¡è¶³ç”¨æˆ·æŒ‡å®šçš„æ—¶é•¿è¦æ±‚
"""
    
    def _build_user_prompt(
        self,
        topic: str,
        num_speakers: int,
        duration_minutes: int,
        language: str,
        speaker_names: Optional[List[str]],
        additional_context: Optional[str] = None,
        custom_instructions: Optional[str] = None
    ) -> str:
        """æ„å»ºç”¨æˆ·æç¤ºè¯"""
        
        duration_seconds = duration_minutes * 60
        
        # æ ¹æ®è¯­è¨€ç¡®å®šå†…å®¹é‡å•ä½å’Œä¼°ç®—å€¼
        if language.startswith("zh") or language.startswith("cmn"):
            # ä¸­æ–‡ï¼šä½¿ç”¨å­—ç¬¦æ•°ï¼Œçº¦3.5å­—ç¬¦/ç§’
            content_estimate = duration_seconds * 3.5
            content_unit = "å­—ç¬¦"
            content_unit_short = "å­—"
        elif language.startswith("ja"):
            # æ—¥æ–‡ï¼šä½¿ç”¨å­—ç¬¦æ•°ï¼Œçº¦4.0å­—ç¬¦/ç§’
            content_estimate = duration_seconds * 4.0
            content_unit = "æ–‡å­—"
            content_unit_short = "æ–‡å­—"
        elif language.startswith("ko"):
            # éŸ©æ–‡ï¼šä½¿ç”¨å­—ç¬¦æ•°ï¼Œçº¦4.5å­—ç¬¦/ç§’
            content_estimate = duration_seconds * 4.5
            content_unit = "ê¸€ì"
            content_unit_short = "ê¸€ì"
        else:
            # è‹±æ–‡åŠå…¶ä»–ï¼šä½¿ç”¨è¯æ•°ï¼Œçº¦2.5è¯/ç§’
            content_estimate = duration_seconds * 2.5
            content_unit = "words"
            content_unit_short = "è¯"
        
        words_estimate = content_estimate  # ä¿æŒå˜é‡åå…¼å®¹
        
        # Only include an explicit speaker list if concrete names were
        # provided by the caller. Otherwise omit it so the LLM can invent
        # realistic human names based on role/gender.
        speaker_list = ""
        if speaker_names:
            speaker_list = "\n".join(
                f"  {i+1}. {name}"
                for i, name in enumerate(speaker_names)
            )
        
        # å¯¹äºå¤šäººå¯¹è¯ï¼Œæ·»åŠ å¼ºåˆ¶è¦æ±‚
        multi_speaker_instruction = ""
        if num_speakers > 1:
            multi_speaker_instruction = f"""
ã€é‡è¦ï¼šå¤šäººå¯¹è¯è¦æ±‚ã€‘
- å¿…é¡»è®©æ‰€æœ‰ {num_speakers} ä½è®²è¯äººéƒ½å……åˆ†å‚ä¸å¯¹è¯
- è®²è¯äººåº”è¯¥è½®æµå‘è¨€ï¼Œå½¢æˆè‡ªç„¶çš„å¯¹è¯æµ
- æ¯ä½è®²è¯äººåº”è¯¥æœ‰ {max(2, num_speakers * 2)} æ¬¡ä»¥ä¸Šçš„å‘è¨€æœºä¼š
- ä¸åŒè®²è¯äººçš„è§‚ç‚¹åº”è¯¥æœ‰å·®å¼‚å’Œäº’åŠ¨
- é¿å…é•¿ç¯‡ç‹¬ç™½ï¼Œä¿ƒè¿›è®¨è®ºå’Œäº’åŠ¨
"""
        
        # Example speakers used inside the prompt when helpful. If
        # speaker_names is provided, use those; otherwise provide generic
        # placeholders in the examples but do not force the model to use
        # them as the canonical list.
        example_speakers = []
        for i in range(min(num_speakers, 4)):
            if speaker_names and i < len(speaker_names):
                example_speakers.append(speaker_names[i])
            else:
                example_speakers.append(f"Speaker {i+1}")
        
        # Build the speaker list block only when available
        speaker_list_block = f"\n{speaker_list}\n" if speaker_list else ""

        # è®¡ç®—æ›´æ¿€è¿›çš„æœ€å°å­—æ•°è¦æ±‚å’Œæ®µè½æ•°
        min_words = int(words_estimate)  # ç›´æ¥ä½¿ç”¨ç›®æ ‡å­—æ•°ï¼Œä¸æ‰“æŠ˜æ‰£
        min_segments = max(15, int(duration_minutes * 3))  # è‡³å°‘æ¯20ç§’ä¸€ä¸ªæ®µè½
        words_per_segment = int(min_words / min_segments)
        
        # æ£€æµ‹æ˜¯å¦æä¾›äº†æºå†…å®¹ï¼ˆçœŸå®æ–°é—»ã€æ•°æ®ç­‰ï¼‰
        has_source_content = additional_context and "ã€é‡è¦ï¼šåŸºäºä»¥ä¸‹çœŸå®å†…å®¹ç”Ÿæˆæ’­å®¢ã€‘" in additional_context
        
        # æ ¹æ®æ˜¯å¦æœ‰æºå†…å®¹ï¼Œè°ƒæ•´promptè¦æ±‚
        if has_source_content:
            content_requirement = f"""
ã€ğŸ”´ ä¸¥æ ¼è¦æ±‚ - å¿…é¡»éµå®ˆã€‘:
1. **ä»…ä½¿ç”¨æä¾›çš„æºå†…å®¹**: ä½ å¿…é¡»ä¸¥æ ¼åŸºäº"é¢å¤–èƒŒæ™¯"ä¸­æä¾›çš„çœŸå®å†…å®¹ç”Ÿæˆæ’­å®¢
2. **ç¦æ­¢ç¼–é€ äº‹å®**: ä¸è¦æ·»åŠ ä»»ä½•æºå†…å®¹ä¸­æ²¡æœ‰æåˆ°çš„æ•°æ®ã€äº‹ä»¶ã€äººåæˆ–å¼•ç”¨
3. **å‡†ç¡®å¼•ç”¨**: å¦‚æœæåˆ°å…·ä½“æ•°å­—ã€æ—¥æœŸã€å…¬å¸åã€äººåï¼Œå¿…é¡»ä¸æºå†…å®¹å®Œå…¨ä¸€è‡´
4. **å¯ä»¥åšçš„**:
   - ç”¨è‡ªå·±çš„è¯é‡æ–°è¡¨è¿°æºå†…å®¹ä¸­çš„ä¿¡æ¯
   - è§£é‡Šå’Œåˆ†ææºå†…å®¹ä¸­çš„æ•°æ®å’Œäº‹ä»¶
   - è®¨è®ºæºå†…å®¹ä¸­æåˆ°çš„äº‹ä»¶çš„å½±å“å’Œæ„ä¹‰
   - åœ¨æºå†…å®¹çš„äº‹å®åŸºç¡€ä¸Šè¿›è¡Œåˆç†æ¨ç†
5. **ä¸å¯ä»¥åšçš„**:
   - ç¼–é€ æºå†…å®¹ä¸­ä¸å­˜åœ¨çš„ç»Ÿè®¡æ•°æ®
   - æåŠæºå†…å®¹ä¸­æœªå‡ºç°çš„å…¬å¸ã€é¡¹ç›®æˆ–äººç‰©
   - æ·»åŠ æºå†…å®¹ä¸­æ²¡æœ‰çš„"ä¸“å®¶è§‚ç‚¹"æˆ–"æœ€æ–°æ¶ˆæ¯"
   - å¤¸å¤§æˆ–æ‰­æ›²æºå†…å®¹ä¸­çš„ä¿¡æ¯

å¦‚æœæºå†…å®¹ä¿¡æ¯ä¸è¶³ä»¥å¡«æ»¡ {duration_minutes} åˆ†é’Ÿï¼Œä½ åº”è¯¥:
- æ·±å…¥åˆ†æå·²æœ‰ä¿¡æ¯çš„å«ä¹‰å’Œå½±å“
- è®¨è®ºäº‹ä»¶çš„èƒŒæ™¯å’Œcontext
- æ¢è®¨å¯èƒ½çš„åç»­å½±å“å’Œè¶‹åŠ¿
- ä½†ä»ç„¶ä¸è¦ç¼–é€ æ–°çš„äº‹å®
"""
        else:
            content_requirement = f"""
ã€å…³é”®è¦æ±‚ - å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘:

1. **é•¿åº¦è¦æ±‚ï¼ˆæœ€é‡è¦ï¼‰**:
   - æ•´ä¸ªè„šæœ¬å¿…é¡»åŒ…å«è‡³å°‘ {min_segments} ä¸ªå¯¹è¯æ®µè½
   - æ€»å†…å®¹é‡å¿…é¡»è¾¾åˆ°æˆ–è¶…è¿‡ {min_words} {content_unit}
   - æ¯ä¸ªæ®µè½åº”è¯¥åŒ…å« {words_per_segment}-{words_per_segment + 50} {content_unit_short}
   - å¦‚æœä½ å‘ç°å†…å®¹ä¸å¤Ÿé•¿ï¼Œå¿…é¡»å¢åŠ æ›´å¤šè®¨è®ºã€ä¸¾ä¾‹ã€ç»†èŠ‚å’Œäº’åŠ¨

2. **å†…å®¹æ·±åº¦è¦æ±‚**:
   - å¯¹ä¸»é¢˜çš„æ¯ä¸ªæ–¹é¢éƒ½è¦æ·±å…¥è®¨è®º
   - åŒ…å«å…·ä½“çš„ä¾‹å­ã€æ•°æ®ã€æ•…äº‹æˆ–æ¡ˆä¾‹
   - è®©è®²è¯äººä¹‹é—´æœ‰å……åˆ†çš„äº’åŠ¨å’Œæ¥å›å¯¹è¯
   - ä¸è¦åŒ†å¿™ç»“æŸè¯é¢˜ï¼Œè¦å……åˆ†å±•å¼€

3. **ç»“æ„è¦æ±‚**:
   - Opening (å¼€åœº): 2-3ä¸ªæ®µè½ï¼Œä»‹ç»ä¸»é¢˜å’Œè®²è¯äºº
   - Main (ä¸»ä½“): è‡³å°‘ {min_segments - 6} ä¸ªæ®µè½ï¼Œæ·±å…¥è®¨è®ºå¤šä¸ªå­è¯é¢˜
   - Closing (ç»“å°¾): 2-3ä¸ªæ®µè½ï¼Œæ€»ç»“è¦ç‚¹
"""
        
        prompt = f"""è¯·ä¸ºä»¥ä¸‹æ’­å®¢ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ã€é«˜è´¨é‡çš„è„šæœ¬ã€‚

ã€æ’­å®¢ä¿¡æ¯ã€‘
- ä¸»é¢˜: {topic}
- è®²è¯äººæ•°: {num_speakers}
{speaker_list_block}- ç›®æ ‡æ—¶é•¿: {duration_minutes} åˆ†é’Ÿï¼ˆ{duration_seconds} ç§’ï¼‰
- å¿…é¡»è¾¾åˆ°çš„æ€»å†…å®¹é‡: è‡³å°‘ {min_words} {content_unit}
- å¿…é¡»åŒ…å«çš„æ®µè½æ•°: è‡³å°‘ {min_segments} ä¸ªæ®µè½
- è¯­è¨€: {language}

ã€é¢å¤–èƒŒæ™¯ã€‘
{additional_context or "æ— "}

ã€è‡ªå®šä¹‰è¦æ±‚ã€‘
{custom_instructions or "éµå¾ªé»˜è®¤é£æ ¼"}
{multi_speaker_instruction}

{content_requirement}

ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘
è¯·è¿”å›ä»¥ä¸‹ JSON ç»“æ„ï¼Œä¸è¦åŒ…å«ä»»ä½•ä»£ç å—æ ‡è®°æˆ–å…¶ä»–æ–‡æœ¬ï¼Œç›´æ¥è¿”å› JSONï¼š

{{
    "title": "æ’­å®¢æ ‡é¢˜",
    "description": "æ’­å®¢ç®€è¿°ï¼ˆä¸€å¥è¯æ¦‚æ‹¬ï¼‰",
    "segments": [
        {{
            "speaker_id": "speaker_1",
            "speaker_name": "{example_speakers[0]}",
            "segment_type": "opening",
            "text": "å¼€åœºç™½ï¼Œåº”è¯¥çƒ­æƒ…æ¬¢è¿å¬ä¼—å¹¶ä»‹ç»ä»Šå¤©çš„ä¸»é¢˜...(çº¦{words_per_segment}{content_unit_short})",
            "notes": "è¯­æ°”çƒ­æƒ…ã€èŠ‚å¥é€‚ä¸­"
        }},
        {{
            "speaker_id": "speaker_2",
            "speaker_name": "{example_speakers[1] if len(example_speakers) > 1 else example_speakers[0]}",
            "segment_type": "opening",
            "text": "ç¬¬äºŒä½è®²è¯äººçš„è‡ªæˆ‘ä»‹ç»å’Œå¯¹ä¸»é¢˜çš„åˆæ­¥çœ‹æ³•...(çº¦{words_per_segment}{content_unit_short})"
        }},
        // ... ç»§ç»­æ·»åŠ æ›´å¤šæ®µè½ï¼Œç¡®ä¿è¾¾åˆ°{min_segments}ä¸ªæ®µè½
        {{
            "speaker_id": "speaker_1",
            "speaker_name": "{example_speakers[0]}",
            "segment_type": "main",
            "text": "æ·±å…¥è®¨è®ºç¬¬ä¸€ä¸ªå­è¯é¢˜ï¼ŒåŒ…å«å…·ä½“ä¾‹å­å’Œç»†èŠ‚...(çº¦{words_per_segment}{content_unit_short})"
        }},
        // ... ä¸»ä½“éƒ¨åˆ†è¦æœ‰å¤§é‡çš„back-and-forthå¯¹è¯
        {{
            "speaker_id": "speaker_1",
            "speaker_name": "{example_speakers[0]}",
            "segment_type": "closing",
            "text": "æ€»ç»“ä»Šå¤©è®¨è®ºçš„è¦ç‚¹ï¼Œæ„Ÿè°¢å¬ä¼—æ”¶å¬...(çº¦{words_per_segment}{content_unit_short})"
        }}
    ]
}}

ã€è´¨é‡æ£€æŸ¥æ¸…å•ã€‘:
- âœ“ æ˜¯å¦æœ‰è‡³å°‘ {min_segments} ä¸ªæ®µè½ï¼Ÿ
- âœ“ æ€»å†…å®¹é‡æ˜¯å¦è¾¾åˆ° {min_words} {content_unit}ï¼Ÿ
- âœ“ æ¯ä¸ªè®²è¯äººæ˜¯å¦éƒ½å……åˆ†å‚ä¸ï¼Ÿ
- âœ“ å†…å®¹æ˜¯å¦æ·±å…¥ã€æœ‰ä»·å€¼ã€ä¿¡æ¯ä¸°å¯Œï¼Ÿ
- âœ“ æ˜¯å¦åŒ…å«å…·ä½“çš„ä¾‹å­å’Œç»†èŠ‚ï¼Ÿ

è¯·ç¡®ä¿ç”Ÿæˆçš„å†…å®¹å®Œæ•´ã€æœ‰æ·±åº¦ï¼Œä¸è¦ä¸ºäº†é€Ÿåº¦è€Œç‰ºç‰²è´¨é‡å’Œé•¿åº¦ã€‚ç›´æ¥è¿”å›JSONï¼Œä¸è¦åŠ ä»»ä½•å…¶ä»–æ–‡æœ¬ã€‚
"""
        
        return prompt
    
    def _generate_speaker_names(
        self,
        num_speakers: int,
        language: str
    ) -> List[str]:
        """ç”Ÿæˆè®²è¯äººåå­—"""
        
        if language.startswith("zh"):
            # ä¸­æ–‡åå­—
            names_pools = {
                1: ["ä¸»æŒäºº"],
                2: ["ä¸»æŒäºº A", "ä¸»æŒäºº B"],
                3: ["ä¸»æŒäºº", "å˜‰å®¾ A", "å˜‰å®¾ B"],
                4: ["ä¸»æŒäºº", "å˜‰å®¾ A", "å˜‰å®¾ B", "å˜‰å®¾ C"],
            }
        elif language.startswith("ko"):
            # éŸ©æ–‡åå­—
            names_pools = {
                1: ["í˜¸ìŠ¤íŠ¸"],
                2: ["í˜¸ìŠ¤íŠ¸ A", "í˜¸ìŠ¤íŠ¸ B"],
                3: ["í˜¸ìŠ¤íŠ¸", "ê²ŒìŠ¤íŠ¸ A", "ê²ŒìŠ¤íŠ¸ B"],
            }
        else:
            # è‹±æ–‡åå­—
            names_pools = {
                1: ["Host"],
                2: ["Host A", "Host B"],
                3: ["Host", "Guest A", "Guest B"],
                4: ["Host", "Guest A", "Guest B", "Guest C"],
            }
        
        return names_pools.get(num_speakers, names_pools[2])
    
    def _parse_script_response(
        self,
        script_data: Dict,
        topic: str,
        tone: PodcastTone,
        dialogue_style: DialogueStyle,
        language: str,
        num_speakers: int,
        template_speaker_ids: Optional[List[str]] = None
    ) -> PodcastScript:
        """è§£æ LLM è¿”å›çš„è„šæœ¬æ•°æ®"""
        
        segments = []
        total_duration = 0.0
        
        # å»ºç«‹ speaker_N åˆ° template_speaker_id çš„æ˜ å°„
        # ä¾‹å¦‚: speaker_1 -> host_male, speaker_2 -> host_female, ...
        speaker_id_map = {}
        if template_speaker_ids:
            for i in range(min(num_speakers, len(template_speaker_ids))):
                speaker_id_map[f"speaker_{i+1}"] = template_speaker_ids[i]
        
        for seg_data in script_data.get("segments", []):
            # ä¼°ç®—æ—¶é•¿ - æ ¹æ®è¯­è¨€ä½¿ç”¨ä¸åŒçš„è®¡ç®—æ–¹å¼
            text = seg_data["text"]
            duration = self._estimate_duration(text, language)
            total_duration += duration
            
            # è½¬æ¢ä¸º SSML æ ¼å¼
            ssml_text = self._text_to_ssml(
                seg_data["text"],
                language
            )
            
            # ä½¿ç”¨ template speaker ID æ˜ å°„
            original_speaker_id = seg_data.get("speaker_id", f"speaker_{len(segments)}")
            final_speaker_id = speaker_id_map.get(original_speaker_id, original_speaker_id)
            
            segment = ScriptSegment(
                speaker_id=final_speaker_id,  # âœ… ä½¿ç”¨æ˜ å°„åçš„ template speaker ID
                speaker_name=seg_data.get("speaker_name", "Unknown"),
                text=seg_data["text"],
                ssml_text=ssml_text,
                duration_seconds=duration,
                segment_type=seg_data.get("segment_type", "main"),
                notes=seg_data.get("notes")
            )
            
            segments.append(segment)
        
        script = PodcastScript(
            topic=topic,
            title=script_data.get("title", f"Podcast: {topic[:50]}"),
            description=script_data.get("description", topic),
            language=language,
            tone=tone,
            dialogue_style=dialogue_style,
            num_speakers=num_speakers,
            estimated_duration_seconds=total_duration,
            segments=segments,
            metadata={
                "model": self.model,
                "generated_at": __import__('datetime').datetime.now().isoformat()
            }
        )
        
        return script
    
    def _expand_script(
        self,
        current_script: PodcastScript,
        target_duration: float,
        language: str,
        tone: PodcastTone,
        dialogue_style: DialogueStyle,
        template_speaker_ids: Optional[List[str]] = None
    ) -> PodcastScript:
        """
        æ‰©å±•ç°æœ‰è„šæœ¬ä»¥è¾¾åˆ°ç›®æ ‡æ—¶é•¿
        
        Args:
            current_script: å½“å‰çš„è„šæœ¬å¯¹è±¡
            target_duration: ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰
            language: è¯­è¨€ä»£ç 
            tone: è¯­è°ƒ
            dialogue_style: å¯¹è¯é£æ ¼
            template_speaker_ids: æ¨¡æ¿speaker IDåˆ—è¡¨ï¼ˆç”¨äºæ˜ å°„ï¼‰
            
        Returns:
            æ‰©å±•åçš„è„šæœ¬å¯¹è±¡
        """
        
        # è®¡ç®—éœ€è¦å¢åŠ çš„æ—¶é•¿
        current_duration = current_script.estimated_duration_seconds
        needed_duration = target_duration - current_duration
        
        # æ ¹æ®è¯­è¨€ç¡®å®šå†…å®¹é‡å•ä½å’Œä¼°ç®—å€¼
        if language.startswith("zh") or language.startswith("cmn"):
            needed_content = int(needed_duration * 3.5)
            content_unit = "å­—ç¬¦"
        elif language.startswith("ja"):
            needed_content = int(needed_duration * 4.0)
            content_unit = "æ–‡å­—"
        elif language.startswith("ko"):
            needed_content = int(needed_duration * 4.5)
            content_unit = "ê¸€ì"
        else:
            needed_content = int(needed_duration * 2.5)
            content_unit = "words"
        
        needed_words = needed_content  # ä¿æŒå˜é‡åå…¼å®¹
        
        # æ„å»ºspeaker IDåˆ°åå­—çš„æ˜ å°„ï¼ˆä»ç°æœ‰æ®µè½ä¸­æå–ï¼‰
        speaker_map = {}
        for seg in current_script.segments:
            if seg.speaker_id not in speaker_map:
                speaker_map[seg.speaker_id] = seg.speaker_name
        
        # æ„å»ºæ‰©å±•æç¤ºè¯ä¸­çš„è®²è¯äººåˆ—è¡¨
        speaker_list_for_prompt = "\n".join([
            f"  - speaker_id: \"{sid}\", speaker_name: \"{sname}\""
            for sid, sname in speaker_map.items()
        ])
        
        # æ„å»ºæ‰©å±•æç¤ºè¯
        current_segments_summary = []
        for i, seg in enumerate(current_script.segments[-5:]):  # åªå–æœ€å5ä¸ªæ®µè½ä½œä¸ºä¸Šä¸‹æ–‡
            current_segments_summary.append(f"{seg.speaker_name} ({seg.speaker_id}): {seg.text[:100]}...")
        
        context_summary = "\n".join(current_segments_summary)
        
        expansion_prompt = f"""å½“å‰æ’­å®¢è„šæœ¬é•¿åº¦ä¸è¶³ï¼Œéœ€è¦ç»§ç»­æ‰©å±•å†…å®¹ã€‚

ã€å½“å‰çŠ¶æ€ã€‘
- ä¸»é¢˜: {current_script.topic}
- å½“å‰æ—¶é•¿: {current_duration:.1f} ç§’
- ç›®æ ‡æ—¶é•¿: {target_duration:.1f} ç§’
- éœ€è¦å¢åŠ : çº¦ {needed_words} {content_unit}

ã€è®²è¯äººä¿¡æ¯ï¼ˆå¿…é¡»ä¸¥æ ¼ä½¿ç”¨è¿™äº›IDå’Œåå­—ï¼‰ã€‘
{speaker_list_for_prompt}

ã€æœ€è¿‘çš„å¯¹è¯å†…å®¹ã€‘
{context_summary}

ã€æ‰©å±•è¦æ±‚ã€‘
è¯·ç»§ç»­è¿™ä¸ªæ’­å®¢çš„è®¨è®ºï¼Œç”Ÿæˆæ›´å¤šæ®µè½æ¥è¾¾åˆ°ç›®æ ‡æ—¶é•¿ï¼š

1. **ç»§ç»­å½“å‰è¯é¢˜**: åœ¨ç°æœ‰è®¨è®ºçš„åŸºç¡€ä¸Šç»§ç»­æ·±å…¥
2. **æ–°çš„å­è¯é¢˜**: å¯ä»¥å¼•å…¥ç›¸å…³çš„æ–°è§’åº¦æˆ–å­è¯é¢˜
3. **å¿…é¡»ä½¿ç”¨ä¸Šè¿°ç²¾ç¡®çš„speaker_id**: ä¾‹å¦‚ä½¿ç”¨ "{list(speaker_map.keys())[0]}" è€Œä¸æ˜¯ "speaker_1" æˆ–å…¶ä»–å˜ä½“
4. **å¿…é¡»ä½¿ç”¨ä¸Šè¿°ç²¾ç¡®çš„speaker_name**: ä¿æŒåå­—å®Œå…¨ä¸€è‡´
5. **è‡ªç„¶è¡”æ¥**: å†…å®¹è¦ä¸å‰é¢çš„å¯¹è¯è‡ªç„¶è¡”æ¥
6. **ç”Ÿæˆè‡³å°‘ {needed_words} {content_unit}**: ç¡®ä¿è¾¾åˆ°æ‰€éœ€çš„é•¿åº¦

è¯·è¿”å›æ‰©å±•çš„æ®µè½æ•°ç»„ï¼Œæ ¼å¼ä¸ä¹‹å‰ç›¸åŒçš„JSONç»“æ„ï¼š

{{
    "segments": [
        {{
            "speaker_id": "{list(speaker_map.keys())[0]}",
            "speaker_name": "{list(speaker_map.values())[0]}",
            "segment_type": "main",
            "text": "ç»§ç»­è®¨è®ºçš„å†…å®¹...",
            "notes": "å¯é€‰çš„å¯¼æ¼”ç¬”è®°"
        }},
        ...æ›´å¤šæ®µè½ä»¥è¾¾åˆ°{needed_words}è¯...
    ]
}}

ç›´æ¥è¿”å›JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡æœ¬ã€‚
"""
        
        try:
            response = self._chat_completions_create_by_model(
                messages=[
                    {"role": "system", "content": f"ä½ æ˜¯æ’­å®¢è„šæœ¬ç¼–å‰§ï¼Œæ“…é•¿æ‰©å±•å’Œä¸°å¯Œå†…å®¹ã€‚è¯­è¨€ï¼š{language}"},
                    {"role": "user", "content": expansion_prompt},
                ],
                max_output_tokens=8000,
                temperature=0.7,
                top_p=0.95,
            )
            
            expansion_json = response.choices[0].message.content
            expansion_data = json.loads(expansion_json)
            
            # æå–tokenä½¿ç”¨ç»Ÿè®¡
            usage_dict = None
            if hasattr(response, 'usage') and response.usage:
                usage_obj = response.usage
                usage_dict = {
                    'prompt_tokens': usage_obj.prompt_tokens,
                    'completion_tokens': usage_obj.completion_tokens,
                    'total_tokens': usage_obj.total_tokens
                }
            
            # è§£ææ–°æ®µè½å¹¶æ·»åŠ åˆ°ç°æœ‰è„šæœ¬
            for seg_data in expansion_data.get("segments", []):
                text = seg_data["text"]
                duration = self._estimate_duration(text, language)
                
                ssml_text = self._text_to_ssml(text, language)
                
                segment = ScriptSegment(
                    speaker_id=seg_data.get("speaker_id", "speaker_1"),
                    speaker_name=seg_data.get("speaker_name", "Unknown"),
                    text=seg_data["text"],
                    ssml_text=ssml_text,
                    duration_seconds=duration,
                    segment_type=seg_data.get("segment_type", "main"),
                    notes=seg_data.get("notes")
                )
                
                current_script.segments.append(segment)
                current_script.estimated_duration_seconds += duration
            
            # æ›´æ–°usageä¿¡æ¯
            if usage_dict:
                current_script.metadata['usage'] = usage_dict
            
            return current_script
            
        except Exception as e:
            logger.error(f"âŒ è„šæœ¬æ‰©å±•å¤±è´¥: {e}")
            # æ‰©å±•å¤±è´¥æ—¶è¿”å›åŸè„šæœ¬
            return current_script
    
    def _estimate_duration(self, text: str, language: str) -> float:
        """
        æ ¹æ®è¯­è¨€æ™ºèƒ½ä¼°ç®—æ–‡æœ¬çš„æ’­æŠ¥æ—¶é•¿
        
        ä¸­æ–‡/æ—¥æ–‡/éŸ©æ–‡: æŒ‰å­—ç¬¦æ•°è®¡ç®—ï¼ˆå› ä¸ºæ¯ä¸ªå­—ç¬¦åŸºæœ¬éƒ½æ˜¯ä¸€ä¸ªå®Œæ•´çš„è¯­ä¹‰å•ä½ï¼‰
        è‹±æ–‡ç­‰: æŒ‰å•è¯æ•°è®¡ç®—
        
        Args:
            text: è¦ä¼°ç®—çš„æ–‡æœ¬
            language: è¯­è¨€ä»£ç 
            
        Returns:
            ä¼°ç®—çš„ç§’æ•°
        """
        # ä¸­æ–‡ç³»è¯­è¨€ï¼ˆåŒ…æ‹¬ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ï¼‰
        if language.startswith("zh") or language.startswith("cmn"):
            # ä¸­æ–‡å¹³å‡è¯­é€Ÿçº¦ 4-5 å­—/ç§’
            # æ’­å®¢é€šå¸¸è¾ƒæ…¢ï¼Œä½¿ç”¨ 3.5 å­—/ç§’
            char_count = len([c for c in text if '\u4e00' <= c <= '\u9fff'])  # åªè®¡ç®—æ±‰å­—
            return char_count / 3.5
        
        # æ—¥æ–‡
        elif language.startswith("ja"):
            # æ—¥æ–‡è¯­é€Ÿç±»ä¼¼ä¸­æ–‡ï¼Œçº¦ 4 å­—/ç§’
            # åŒ…å«å¹³å‡åã€ç‰‡å‡åã€æ±‰å­—
            char_count = len([c for c in text if (
                ('\u3040' <= c <= '\u309f') or  # å¹³å‡å
                ('\u30a0' <= c <= '\u30ff') or  # ç‰‡å‡å
                ('\u4e00' <= c <= '\u9fff')     # æ±‰å­—
            )])
            return char_count / 4.0
        
        # éŸ©æ–‡
        elif language.startswith("ko"):
            # éŸ©æ–‡è¯­é€Ÿçº¦ 4-5 å­—/ç§’
            char_count = len([c for c in text if '\uac00' <= c <= '\ud7af'])  # éŸ©æ–‡å­—ç¬¦
            return char_count / 4.5
        
        # è‹±æ–‡ç­‰è¥¿æ–¹è¯­è¨€ï¼ˆé»˜è®¤ï¼‰
        else:
            # è‹±æ–‡å¹³å‡è¯­é€Ÿçº¦ 150-160 è¯/åˆ†é’Ÿ
            # å³ 2.5-2.7 è¯/ç§’ï¼Œæ’­å®¢é€šå¸¸è¾ƒæ…¢ï¼Œä½¿ç”¨ 2.5 è¯/ç§’
            word_count = len(text.split())
            return word_count / 2.5
    
    def _text_to_ssml(self, text: str, language: str) -> str:
        """å°†æ–‡æœ¬è½¬æ¢ä¸º SSML æ ¼å¼"""
        
        # åŸºç¡€ SSML åŒ…è£…
        ssml = f'<speak>{text}</speak>'
        
        # æ·»åŠ è¯­è¨€å’Œè¯­éŸ³å±æ€§
        if language.startswith("zh"):
            # ä¸­æ–‡ï¼šæ·»åŠ æ–­å¥å’Œè‡ªç„¶åœé¡¿
            ssml = ssml.replace("ã€‚", '<break time="500ms"/>')
            ssml = ssml.replace("ï¼Œ", '<break time="200ms"/>')
        elif language.startswith("en"):
            # è‹±æ–‡ï¼šæ·»åŠ é‡éŸ³å’Œåœé¡¿
            ssml = ssml.replace("!", '<emphasis level="strong">!</emphasis><break time="300ms"/>')
            ssml = ssml.replace("?", '<break time="300ms"/>')
        
        return ssml
    
    def save_script(
        self,
        script: PodcastScript,
        output_path: str
    ) -> None:
        """ä¿å­˜è„šæœ¬ä¸º JSON æ–‡ä»¶"""
        
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(script.to_dict(), f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… è„šæœ¬å·²ä¿å­˜: {output_path}")


# ============================================================================
# æ¼”ç¤ºç”¨æ³•
# ============================================================================

def main():
    """æ¼”ç¤ºè„šæœ¬ç”Ÿæˆ"""
    
    print("\n" + "="*80)
    print("ğŸ™ï¸  LLM æ’­å®¢è„šæœ¬ç”Ÿæˆå™¨æ¼”ç¤º".center(80))
    print("="*80 + "\n")
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = LLMScriptGenerator(model="gpt-4-mini")
    
    # ç¤ºä¾‹ 1: åŠ å·æ—…æ¸¸
    print("ã€ç¤ºä¾‹ 1ã€‘åŠ å·æ—…æ¸¸æ’­å®¢")
    print("-" * 80)
    
    script1 = generator.generate_script(
        topic="åŠ å·æ—…æ¸¸å¿…å»çš„æ™¯ç‚¹å’Œä½“éªŒï¼ŒåŒ…æ‹¬æ—§é‡‘å±±ã€æ´›æ‰çŸ¶ã€åœ£åœ°äºšå“¥ç­‰åœ°çš„æ¨è",
        num_speakers=2,
        duration_minutes=5,
        language="zh-CN",
        tone=PodcastTone.ENTERTAINING,
        dialogue_style=DialogueStyle.CONVERSATION,
        speaker_names=["Amy", "Tom"],
        additional_context="ç›®æ ‡å¬ä¼—æ˜¯è®¡åˆ’å»åŠ å·æ—…æ¸¸çš„å¹´è½»äºº"
    )
    
    print(f"âœ… ç”Ÿæˆå®Œæˆ!")
    print(f"   æ ‡é¢˜: {script1.title}")
    print(f"   æè¿°: {script1.description}")
    print(f"   æ®µè½: {len(script1.segments)}")
    print(f"   æ—¶é•¿: {script1.estimated_duration_seconds:.1f} ç§’")
    print()
    
    # ä¿å­˜è„šæœ¬
    script1.save_path = "outputs/script_california_tour.json"
    generator.save_script(script1, script1.save_path)
    
    # ç¤ºä¾‹ 2: GPU é€‰è´­æŒ‡å—
    print("\nã€ç¤ºä¾‹ 2ã€‘GPU é€‰è´­æŒ‡å—æ’­å®¢")
    print("-" * 80)
    
    script2 = generator.generate_script(
        topic="2025å¹´GPUæ˜¾å¡é€‰è´­æŒ‡å—ï¼Œå¯¹æ¯”NVIDIA RTXå’ŒAMDçš„æ€§èƒ½å’Œä»·æ ¼ï¼Œé€‚åˆæ¸¸æˆå’ŒAIåº”ç”¨",
        num_speakers=2,
        duration_minutes=5,
        language="zh-CN",
        tone=PodcastTone.EDUCATIONAL,
        dialogue_style=DialogueStyle.INTERVIEW,
        speaker_names=["ä¸»æŒäººå°æ", "ç¡¬ä»¶ä¸“å®¶ç‹åšå£«"],
        additional_context="ç›®æ ‡å¬ä¼—æ˜¯æƒ³è¦å‡çº§GPUçš„å¼€å‘è€…å’Œæ¸¸æˆç©å®¶"
    )
    
    print(f"âœ… ç”Ÿæˆå®Œæˆ!")
    print(f"   æ ‡é¢˜: {script2.title}")
    print(f"   æ®µè½: {len(script2.segments)}")
    print(f"   æ—¶é•¿: {script2.estimated_duration_seconds:.1f} ç§’")
    
    generator.save_script(script2, "outputs/script_gpu_guide.json")
    
    print("\nâœ… æ‰€æœ‰è„šæœ¬ç”Ÿæˆå®Œæˆ!")


if __name__ == "__main__":
    main()
