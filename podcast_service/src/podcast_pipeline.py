#!/usr/bin/env python3
"""
===============================================================================
AIæ’­å®¢ç”ŸæˆPipeline - ç”Ÿäº§çº§ç³»ç»Ÿ
===============================================================================
æ”¯æŒï¼š
  1. æ¨¡æ¿åŒ–é…ç½® (YAML)
  2. åŠ¨æ€å†…å®¹æ³¨å…¥ (æ–°é—»ã€æ•°æ®ã€è¯„è®º)
  3. AIç”Ÿæˆå¯¹è¯ (ä½¿ç”¨LLM)
  4. æ‰¹é‡ç”Ÿæˆ (å¤šé›†å¹¶è¡Œ)
  5. GCPéƒ¨ç½²å°±ç»ª
===============================================================================
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from enum import Enum
import yaml
from datetime import datetime
from google.cloud import texttospeech
from pydub import AudioSegment
import io

# ============================================================================
# æ—¥å¿—é…ç½®
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# è¯­è¨€ä»£ç æ˜ å°„ - å¤„ç†TTSå’ŒLLMä¹‹é—´çš„è¯­è¨€ä»£ç å·®å¼‚
# ============================================================================

# Google TTSä½¿ç”¨cmn-CNï¼Œä½†OpenAI LLMä½¿ç”¨zh-CN
# è¿™ä¸ªæ˜ å°„è¡¨å°†TTSè¯­è¨€ä»£ç è½¬æ¢ä¸ºLLMè¯­è¨€ä»£ç 
LANGUAGE_CODE_MAPPING = {
    # TTSè¯­è¨€ä»£ç  -> LLMè¯­è¨€ä»£ç 
    "cmn-CN": "zh-CN",      # ç®€ä½“ä¸­æ–‡
    "cmn-TW": "zh-TW",      # ç¹ä½“ä¸­æ–‡
    "yue-HK": "zh-HK",      # ç²¤è¯­ï¼ˆé¦™æ¸¯ï¼‰
    "en-US": "en-US",       # ç¾å¼è‹±è¯­ï¼ˆæ— éœ€è½¬æ¢ï¼‰
    "en-GB": "en-GB",       # è‹±å¼è‹±è¯­ï¼ˆæ— éœ€è½¬æ¢ï¼‰
    "ko-KR": "ko-KR",       # éŸ©è¯­ï¼ˆæ— éœ€è½¬æ¢ï¼‰
    "ja-JP": "ja-JP",       # æ—¥è¯­ï¼ˆæ— éœ€è½¬æ¢ï¼‰
}

def get_llm_language_code(tts_language_code: str) -> str:
    """
    å°†TTSè¯­è¨€ä»£ç è½¬æ¢ä¸ºLLMè¯­è¨€ä»£ç 
    
    Args:
        tts_language_code: Google TTSä½¿ç”¨çš„è¯­è¨€ä»£ç 
        
    Returns:
        OpenAI LLMä½¿ç”¨çš„è¯­è¨€ä»£ç 
    """
    return LANGUAGE_CODE_MAPPING.get(tts_language_code, tts_language_code)

def get_tts_language_code(llm_language_code: str) -> str:
    """
    å°†LLMè¯­è¨€ä»£ç è½¬æ¢ä¸ºTTSè¯­è¨€ä»£ç ï¼ˆåå‘æ˜ å°„ï¼‰
    
    Args:
        llm_language_code: OpenAI LLMä½¿ç”¨çš„è¯­è¨€ä»£ç 
        
    Returns:
        Google TTSä½¿ç”¨çš„è¯­è¨€ä»£ç 
    """
    # åˆ›å»ºåå‘æ˜ å°„
    reverse_mapping = {v: k for k, v in LANGUAGE_CODE_MAPPING.items()}
    return reverse_mapping.get(llm_language_code, llm_language_code)

# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

class SpeakerRole(Enum):
    """è®²è¯äººè§’è‰²"""
    HOST = "Host"
    CO_HOST = "Co-host"
    EXPERT = "Expert"
    GUEST = "Guest"
    INVESTOR = "Investor"
    ANALYST = "Analyst"

@dataclass
class Speaker:
    """è®²è¯äººä¿¡æ¯"""
    id: str
    name: str
    role: SpeakerRole
    voice_name: str
    language_code: str
    gender: str

@dataclass
class DialogueSegment:
    """å¯¹è¯æ®µè½"""
    speaker_id: str
    text: str
    estimated_duration_seconds: float = 0.0
    audio_bytes: Optional[bytes] = None
    
@dataclass
class PodcastConfig:
    """æ’­å®¢é…ç½®"""
    template_name: str
    name: str
    language: str
    duration_minutes: int
    speakers: List[Speaker] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class NewsData:
    """æ–°é—»æ•°æ®æ³¨å…¥"""
    headlines: List[str]
    key_stats: Dict[str, str]
    sentiment: str  # "bullish", "bearish", "neutral"
    quotes: List[str]

# ============================================================================
# æ¨¡æ¿ç®¡ç†å™¨
# ============================================================================

class TemplateManager:
    """åŠ è½½å’Œç®¡ç†YAMLæ¨¡æ¿"""
    
    def __init__(self, config_path: str = "config/podcast_style_templates.yaml"):
        self.config_path = Path(config_path)
        self.templates = self._load_templates()
    
    def _load_templates(self) -> Dict:
        """ä»YAMLåŠ è½½æ¨¡æ¿"""
        if not self.config_path.exists():
            logger.warning(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
            return {}
        
        with open(self.config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        logger.info(f"âœ… åŠ è½½æ¨¡æ¿: {list(config.get('styles', {}).keys())}")
        return config
    
    def get_template(self, template_name: str) -> Dict:
        """è·å–ç‰¹å®šæ¨¡æ¿"""
        return self.templates.get('styles', {}).get(template_name, {})
    
    def list_templates(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡æ¿"""
        return list(self.templates.get('styles', {}).keys())

# ============================================================================
# å†…å®¹ç”Ÿæˆå™¨ (LLMé›†æˆç‚¹)
# ============================================================================

class ContentGenerator:
    """
    ä½¿ç”¨LLMç”Ÿæˆæ’­å®¢å†…å®¹
    æ”¯æŒ: mock (å¿«é€Ÿæ¼”ç¤º) | openai (GPT-4-mini) | anthropic (å¾…å®ç°) | vertex_ai (å¾…å®ç°)
    """
    
    def __init__(self, model: str = "openai", api_key: Optional[str] = None):
        """
        model: "mock" | "openai" | "anthropic" | "vertex_ai"
        api_key: API å¯†é’¥ (å¦‚æœä¸º None åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–)
        """
        self.model = model
        self.api_key = api_key
        self.llm_generator = None
        
        if model == "openai":
            try:
                from src.llm_script_generator import LLMScriptGenerator, PodcastTone, DialogueStyle
                self.llm_generator = LLMScriptGenerator(api_key=api_key)
                logger.info(f"âœ… åˆå§‹åŒ– OpenAI å†…å®¹ç”Ÿæˆå™¨: {model}")
            except Exception as e:
                logger.warning(f"âš ï¸  OpenAI åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ° mock æ¨¡å¼: {e}")
                self.model = "mock"
        else:
            logger.info(f"åˆå§‹åŒ–å†…å®¹ç”Ÿæˆå™¨: {model}")
    
    def generate_dialogue(
        self,
        topic: str,
        speakers: List[Speaker],
        segment_type: str,
        context: Optional[Dict] = None
    ) -> str:
        """
        ä½¿ç”¨LLMç”Ÿæˆè‡ªç„¶å¯¹è¯
        
        Args:
            topic: è®¨è®ºä¸»é¢˜
            speakers: è®²è¯äººåˆ—è¡¨
            segment_type: æ®µè½ç±»å‹ (opening, analysis, conclusionç­‰)
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ (æ–°é—»ã€æ•°æ®ç­‰)
        
        Returns:
            ç”Ÿæˆçš„å¯¹è¯æ–‡æœ¬ (SSMLæ ¼å¼)
        """
        
        if self.model == "mock":
            return self._generate_mock_dialogue(topic, speakers, segment_type, context)
        elif self.model == "openai":
            return self._generate_openai_dialogue(topic, speakers, segment_type, context)
        elif self.model == "anthropic":
            return self._generate_anthropic_dialogue(topic, speakers, segment_type, context)
        else:
            raise ValueError(f"æœªçŸ¥æ¨¡å‹: {self.model}")
    
    def _generate_mock_dialogue(
        self,
        topic: str,
        speakers: List[Speaker],
        segment_type: str,
        context: Optional[Dict] = None
    ) -> str:
        """Mockå®ç° - ç”¨äºæ¼”ç¤º"""
        
        mock_templates = {
            "opening_en": '<speak>Welcome to our show. I\'m {speaker}. Today we discuss {topic}.</speak>',
            "analysis_en": '<speak>{speaker} explains: {topic} is important because <break time="300ms"/> it affects market dynamics.</speak>',
            "reaction_en": '<speak><emphasis level="strong">Wow!</emphasis> <break time="300ms"/> That\'s really interesting!</speak>',
            "opening_ko": '<speak>ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” {speaker}ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ {topic}ì— ëŒ€í•´ ì–˜ê¸°í•˜ê² ìŠµë‹ˆë‹¤.</speak>',
        }
        
        template_key = f"{segment_type}_{speakers[0].language_code.split('-')[0]}"
        template = mock_templates.get(template_key, '<speak>Default content</speak>')
        
        return template.format(speaker=speakers[0].name, topic=topic)
    
    def _generate_openai_dialogue(self, topic, speakers, segment_type, context):
        """é›†æˆOpenAI GPT API"""
        # å®ç°ç¤ºä¾‹
        # from openai import OpenAI
        # client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        # response = client.chat.completions.create(...)
        pass
    
    def _generate_anthropic_dialogue(self, topic, speakers, segment_type, context):
        """é›†æˆAnthropic Claude API"""
        # å®ç°ç¤ºä¾‹
        # from anthropic import Anthropic
        # client = Anthropic()
        # response = client.messages.create(...)
        pass

# ============================================================================
# å¯¹è¯æ„å»ºå™¨
# ============================================================================

class DialogueBuilder:
    """æ„å»ºæ’­å®¢å¯¹è¯åºåˆ—"""
    
    def __init__(self, config: PodcastConfig, content_gen: ContentGenerator):
        self.config = config
        self.content_gen = content_gen
        self.segments: List[DialogueSegment] = []
    
    def build_from_template(
        self,
        template: Dict,
        data: Optional[NewsData] = None
    ) -> List[DialogueSegment]:
        """
        ä»æ¨¡æ¿æ„å»ºå®Œæ•´å¯¹è¯
        
        Args:
            template: ä»TemplateManagerè·å–çš„æ¨¡æ¿
            data: æ–°é—»/æ•°æ®æ³¨å…¥
        
        Returns:
            å¯¹è¯æ®µè½åˆ—è¡¨
        """
        
        logger.info(f"ğŸ“ æ ¹æ®æ¨¡æ¿æ„å»ºå¯¹è¯åºåˆ—...")
        self.segments = []
        
        structure = template.get('structure', {})
        
        for segment_name, segment_config in structure.items():
            logger.info(f"  æ„å»º {segment_name}...")
            
            # è·å–æ­¤æ®µè½çš„è®²è¯äºº
            speaker_ids = segment_config.get('speakers', [])
            speakers = [s for s in self.config.speakers if s.id in speaker_ids]
            
            # ç”Ÿæˆå¯¹è¯å†…å®¹
            text = self.content_gen.generate_dialogue(
                topic=self.config.metadata.get('topic', 'General Discussion'),
                speakers=speakers,
                segment_type=segment_name,
                context=data.__dict__ if data else None
            )
            
            # ä¼°ç®—æ—¶é•¿
            word_count = len(text.split())
            estimated_duration = word_count / 2.5  # çº¦2.5å­—/ç§’
            
            # åˆ›å»ºæ®µè½
            segment = DialogueSegment(
                speaker_id=speakers[0].id if speakers else "unknown",
                text=text,
                estimated_duration_seconds=estimated_duration
            )
            
            self.segments.append(segment)
        
        logger.info(f"âœ… æ„å»ºå®Œæˆ: {len(self.segments)} ä¸ªæ®µè½")
        return self.segments

# ============================================================================
# TTSåˆæˆå¼•æ“
# ============================================================================

class TTSSynthesizer:
    """Google Cloud TTSåˆæˆ"""
    
    def __init__(self, project_id: str = None):
        self.project_id = project_id or os.getenv('GOOGLE_CLOUD_PROJECT')
        self.client = texttospeech.TextToSpeechClient()
        self.audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            sample_rate_hertz=22050,
            speaking_rate=1.0,
            pitch=0.0,
        )
    
    def synthesize_segment(self, segment: DialogueSegment, speaker: Speaker) -> bytes:
        """åˆæˆå•ä¸ªæ®µè½"""
        
        request = texttospeech.SynthesizeSpeechRequest(
            input=texttospeech.SynthesisInput(ssml=segment.text),
            voice=texttospeech.VoiceSelectionParams(
                language_code=speaker.language_code,
                name=speaker.voice_name,
            ),
            audio_config=self.audio_config,
        )
        
        response = self.client.synthesize_speech(request=request)
        return response.audio_content
    
    def synthesize_all(
        self,
        segments: List[DialogueSegment],
        speaker_map: Dict[str, Speaker]
    ) -> List[DialogueSegment]:
        """æ‰¹é‡åˆæˆ"""
        
        logger.info(f"ğŸ”Š åˆæˆ {len(segments)} ä¸ªæ®µè½...")
        
        for idx, segment in enumerate(segments, 1):
            speaker = speaker_map.get(segment.speaker_id)
            if not speaker:
                logger.warning(f"æœªæ‰¾åˆ°è®²è¯äºº: {segment.speaker_id}")
                continue
            
            logger.info(f"  [{idx}/{len(segments)}] åˆæˆ {speaker.name}...")
            
            try:
                audio_bytes = self.synthesize_segment(segment, speaker)
                segment.audio_bytes = audio_bytes
                logger.info(f"    âœ… æˆåŠŸ")
            except Exception as e:
                logger.error(f"    âŒ å¤±è´¥: {str(e)}")
                raise
        
        return segments

# ============================================================================
# éŸ³é¢‘æ··éŸ³å™¨
# ============================================================================

class AudioMixer:
    """æ··åˆå’Œè¾“å‡ºéŸ³é¢‘"""
    
    def __init__(self, output_dir: str = "data/generated_podcasts"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def merge_segments(
        self,
        segments: List[DialogueSegment],
        pause_ms: int = 200
    ) -> AudioSegment:
        """åˆå¹¶æ‰€æœ‰æ®µè½"""
        
        logger.info(f"ğŸ“¦ æ··éŸ³ {len(segments)} ä¸ªæ®µè½...")
        
        silence = AudioSegment.silent(duration=pause_ms)
        merged = None
        
        for segment in segments:
            if segment.audio_bytes is None:
                logger.warning(f"è·³è¿‡ç©ºæ®µè½")
                continue
            
            audio = AudioSegment.from_mp3(io.BytesIO(segment.audio_bytes))
            
            if merged is None:
                merged = audio
            else:
                merged += silence + audio
        
        if merged is None:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ®µè½")
        
        logger.info(f"âœ… æ··éŸ³å®Œæˆ: {len(merged)/1000:.1f} ç§’")
        return merged
    
    def export(
        self,
        audio: AudioSegment,
        podcast_name: str,
        format: str = "mp3",
        bitrate: str = "192k"
    ) -> Path:
        """å¯¼å‡ºéŸ³é¢‘"""
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{podcast_name}_{timestamp}.{format}"
        filepath = self.output_dir / filename
        
        logger.info(f"ğŸ’¾ å¯¼å‡ºåˆ°: {filepath}")
        
        audio.export(str(filepath), format=format, bitrate=bitrate)
        
        file_size_mb = filepath.stat().st_size / (1024 * 1024)
        duration_seconds = len(audio) / 1000
        
        logger.info(f"   æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
        logger.info(f"   æ—¶é•¿: {int(duration_seconds/60)}åˆ†{int(duration_seconds%60)}ç§’")
        
        return filepath

# ============================================================================
# æ’­å®¢ç”ŸæˆPipeline (ä¸»ç±»)
# ============================================================================

class PodcastPipeline:
    """å®Œæ•´çš„æ’­å®¢ç”ŸæˆPipeline"""
    
    def __init__(
        self,
        template_config: str = "config/podcast_style_templates.yaml",
        content_model: str = "openai"
    ):
        self.template_manager = TemplateManager(template_config)
        self.content_generator = ContentGenerator(model=content_model)
        self.synthesizer = TTSSynthesizer()
        self.mixer = AudioMixer()
    
    def generate(
        self,
        template_name: str,
        podcast_name: str,
        topic: str,
        data: Optional[NewsData] = None,
        custom_metadata: Optional[Dict] = None
    ) -> Path:
        """
        ç”Ÿæˆå®Œæ•´æ’­å®¢
        
        Args:
            template_name: æ¨¡æ¿åç§° (å¦‚ "us_stocks_dualhosts")
            podcast_name: æ’­å®¢åç§°
            topic: è®¨è®ºä¸»é¢˜
            data: æ–°é—»/æ•°æ®æ³¨å…¥
            custom_metadata: è‡ªå®šä¹‰å…ƒæ•°æ®
        
        Returns:
            ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        
        logger.info('ğŸ™ï¸ å¼€å§‹ç”Ÿæˆæ’­å®¢...')
        logger.info(f'   æ¨¡æ¿: {template_name}')
        logger.info(f'   ä¸»é¢˜: {topic}')
        logger.info('')
        
        # 1. è·å–æ¨¡æ¿
        template = self.template_manager.get_template(template_name)
        if not template:
            raise ValueError(f"æ¨¡æ¿ä¸å­˜åœ¨: {template_name}")
        
        # 2. æ„å»ºé…ç½®
        config = self._build_config(template, podcast_name, topic, custom_metadata)
        
        # 3. æ„å»ºå¯¹è¯
        dialogue_builder = DialogueBuilder(config, self.content_generator)
        segments = dialogue_builder.build_from_template(template, data)
        
        # 4. åˆæˆéŸ³é¢‘
        speaker_map = {s.id: s for s in config.speakers}
        segments = self.synthesizer.synthesize_all(segments, speaker_map)
        
        # 5. æ··éŸ³
        audio = self.mixer.merge_segments(segments)
        
        # 6. å¯¼å‡º
        output_path = self.mixer.export(audio, podcast_name)
        
        logger.info('âœ… æ’­å®¢ç”ŸæˆæˆåŠŸ!\n')
        
        return output_path
    
    def _build_config(
        self,
        template: Dict,
        podcast_name: str,
        topic: str,
        custom_metadata: Optional[Dict] = None
    ) -> PodcastConfig:
        """æ„å»ºæ’­å®¢é…ç½®"""
        
        # è§£æè®²è¯äºº
        speakers = []
        for speaker_data in template.get('speakers', []):
            # è½¬æ¢role: "Co-host" -> "CO_HOST", "Expert" -> "EXPERT"
            role_str = speaker_data['role'].upper().replace('-', '_')
            speaker = Speaker(
                id=speaker_data['id'],
                name=speaker_data['name'],
                role=SpeakerRole[role_str],
                voice_name=speaker_data['voice_name'],
                language_code=template.get('language', 'en-US'),
                gender=speaker_data['gender']
            )
            speakers.append(speaker)
        
        # æ„å»ºå…ƒæ•°æ®
        metadata = {
            'topic': topic,
            'template_name': template.get('name'),
            'created_at': datetime.now().isoformat(),
        }
        if custom_metadata:
            metadata.update(custom_metadata)
        
        return PodcastConfig(
            template_name=template.get('name'),
            name=podcast_name,
            language=template.get('language', 'en-US'),
            duration_minutes=template.get('duration_minutes', 5),
            speakers=speakers,
            metadata=metadata
        )

# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

def main():
    """æ¼”ç¤ºä½¿ç”¨"""
    
    # åˆå§‹åŒ–Pipeline
    pipeline = PodcastPipeline(
        template_config="config/podcast_style_templates.yaml",
        content_model="openai"  # ä½¿ç”¨ openai å†…å®¹ç”Ÿæˆï¼ˆæ˜¨å¤©éªŒè¯è¿‡çš„æ–¹å¼ï¼‰
    )
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡æ¿
    logger.info("ğŸ“‹ å¯ç”¨æ¨¡æ¿:")
    for template_name in pipeline.template_manager.list_templates():
        logger.info(f"   - {template_name}")
    logger.info('')
    
    # ç¤ºä¾‹1: ç”Ÿæˆç¾è‚¡è®¨è®ºæ’­å®¢
    logger.info("="*70)
    logger.info("ç¤ºä¾‹1: ç¾è‚¡è®¨è®º")
    logger.info("="*70)
    
    output_path = pipeline.generate(
        template_name="english_2_hosts",
        podcast_name="stocks_daily",
        topic="S&P 500 reaches new all-time high",
        custom_metadata={
            'category': 'finance',
            'language': 'English',
        }
    )
    
    logger.info(f"è¾“å‡º: {output_path}\n")
    
    # ç¤ºä¾‹2: ç”ŸæˆéŸ©è¯­Cryptoæ’­å®¢
    logger.info("="*70)
    logger.info("ç¤ºä¾‹2: éŸ©è¯­Cryptoè®¨è®º")
    logger.info("="*70)
    
    crypto_data = NewsData(
        headlines=[
            "Bitcoin breaks $42,000",
            "Ethereum Layer 2 adoption increases"
        ],
        key_stats={
            "BTC": "$42,500",
            "ETH": "$2,200",
            "Market Cap": "$1.2T"
        },
        sentiment="bullish",
        quotes=[
            "Institutional adoption accelerating",
            "Regulatory clarity improving"
        ]
    )
    
    output_path = pipeline.generate(
        template_name="korean_crypto_threeway",
        podcast_name="crypto_korean",
        topic="Crypto Market Update",
        data=crypto_data,
        custom_metadata={
            'category': 'crypto',
            'language': 'Korean',
        }
    )
    
    logger.info(f"è¾“å‡º: {output_path}\n")

if __name__ == '__main__':
    main()
