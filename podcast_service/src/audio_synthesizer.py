#!/usr/bin/env python3
"""
éŸ³é¢‘åˆæˆå™¨ - å°†æ’­å®¢è„šæœ¬åˆæˆä¸º MP3 éŸ³é¢‘
ä½¿ç”¨ Google Cloud Text-to-Speech å’Œ pydub çš„æ–¹å¼
ï¼ˆå¤ç”¨æ˜¨å¤©éªŒè¯è¿‡çš„æŠ€æœ¯ï¼‰
"""

import os
import io
import logging
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime

from google.cloud import texttospeech
from pydub import AudioSegment

# Import cost calculator
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))
from cost_calculator import UsageMetrics

# ============================================================================
# æ—¥å¿—é…ç½®
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

@dataclass
class SpeakerVoiceConfig:
    """è®²è¯äººå£°éŸ³é…ç½®"""
    speaker_id: str
    speaker_name: str
    language_code: str
    voice_name: str
    ssml_gender: texttospeech.SsmlVoiceGender

# ============================================================================
# éŸ³é¢‘åˆæˆå™¨
# ============================================================================

class AudioSynthesizer:
    """
    ä½¿ç”¨ Google Cloud TTS å’Œ pydub åˆæˆæ’­å®¢éŸ³é¢‘
    è¿™æ˜¯æ˜¨å¤©éªŒè¯è¿‡çš„æˆåŠŸæ–¹æ³•
    """
    
    def __init__(self, project_id: str = None, speaking_rate: float = 1.0):
        """åˆå§‹åŒ–åˆæˆå™¨
        
        Args:
            project_id: Google Cloud é¡¹ç›® ID
            speaking_rate: è¯­é€Ÿ (0.5 = æ…¢é€Ÿ, 1.0 = æ­£å¸¸, 1.5 = å¿«é€Ÿ, æœ€å¤§ 2.0)
        """
        self.project_id = project_id or os.getenv('GOOGLE_CLOUD_PROJECT', 'able-engine-466308-q2')
        self.client = texttospeech.TextToSpeechClient()
        self.output_dir = Path('data/generated_podcasts')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # éŸ³é¢‘é…ç½®ï¼ˆæ”¯æŒåŠ¨æ€è¯­é€Ÿï¼‰
        self.audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            sample_rate_hertz=22050,
            speaking_rate=speaking_rate,
            pitch=0.0,
        )
        
        logger.info(f"âœ… éŸ³é¢‘åˆæˆå™¨åˆå§‹åŒ–å®Œæˆ (é¡¹ç›®: {self.project_id}, è¯­é€Ÿ: {speaking_rate}x)")
    
    def synthesize_segment(self, ssml_text: str, voice_config: SpeakerVoiceConfig) -> tuple:
        """
        åˆæˆå•ä¸ªéŸ³é¢‘æ®µè½
        
        Args:
            ssml_text: SSML æ ¼å¼çš„æ–‡æœ¬
            voice_config: è®²è¯äººå£°éŸ³é…ç½®
        
        Returns:
            (MP3å­—èŠ‚æ•°æ®, å­—ç¬¦æ•°)
        """
        try:
            request = texttospeech.SynthesizeSpeechRequest(
                input=texttospeech.SynthesisInput(ssml=ssml_text),
                voice=texttospeech.VoiceSelectionParams(
                    language_code=voice_config.language_code,
                    name=voice_config.voice_name,
                    ssml_gender=voice_config.ssml_gender,
                ),
                audio_config=self.audio_config,
            )
            
            response = self.client.synthesize_speech(request=request)
            # Count characters in SSML text (excluding SSML tags)
            import re
            text_only = re.sub(r'<[^>]+>', '', ssml_text)
            char_count = len(text_only)
            return response.audio_content, char_count
        
        except Exception as e:
            logger.error(f"âŒ åˆæˆå¤±è´¥ ({voice_config.speaker_name}): {e}")
            raise
    
    def generate_from_script(
        self,
        script_data: Dict,
        podcast_name: str = None,
        speaker_voice_map: Dict[str, SpeakerVoiceConfig] = None
    ) -> tuple:
        """
        ä»è„šæœ¬æ•°æ®ç”Ÿæˆå®Œæ•´æ’­å®¢ MP3
        
        Args:
            script_data: LLMScriptGenerator ç”Ÿæˆçš„è„šæœ¬ JSON
            podcast_name: æ’­å®¢åç§°ï¼ˆè‡ªåŠ¨ç”Ÿæˆå¦‚æœä¸ºç©ºï¼‰
            speaker_voice_map: è®²è¯äººåˆ°å£°éŸ³çš„æ˜ å°„
        
        Returns:
            (ç”Ÿæˆçš„MP3æ–‡ä»¶è·¯å¾„, TTSå­—ç¬¦æ•°, éŸ³é¢‘æ—¶é•¿ç§’, æ–‡ä»¶å¤§å°å­—èŠ‚)
        """
        
        # ç”Ÿæˆæ–‡ä»¶åï¼špodcast_{å†…å®¹æè¿°}_{æ—¶é—´æˆ³}
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if not podcast_name:
            # ä»è„šæœ¬æ ‡é¢˜ç”Ÿæˆæè¿°ï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œåªä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
            title = script_data.get('title', 'podcast')
            # å°†æ ‡é¢˜è½¬ä¸ºå°å†™ï¼Œæ›¿æ¢ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ä¸ºä¸‹åˆ’çº¿
            description = ''.join(
                c if c.isalnum() or c == '_' else '_' 
                for c in title.lower()
            )
            # ç§»é™¤è¿ç»­çš„ä¸‹åˆ’çº¿
            description = '_'.join(filter(None, description.split('_')))
            podcast_name = f"podcast_{description}_{timestamp}"
        else:
            podcast_name = f"podcast_{podcast_name}_{timestamp}"
        
        logger.info(f"\nğŸ™ï¸ å¼€å§‹ç”Ÿæˆæ’­å®¢éŸ³é¢‘...")
        logger.info(f"   æ ‡é¢˜: {script_data.get('title')}")
        logger.info(f"   ä¸»é¢˜: {script_data.get('topic')}")
        logger.info(f"   è®²è¯äººæ•°: {script_data.get('num_speakers')}")
        logger.info(f"   æ—¶é•¿: ~{script_data.get('estimated_duration_seconds'):.0f}ç§’")
        logger.info(f"   æ–‡ä»¶å: podcast_{podcast_name}.mp3")
        logger.info("")
        
        # é»˜è®¤å£°éŸ³æ˜ å°„ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if not speaker_voice_map:
            speaker_voice_map = self._get_default_voice_map(
                script_data.get('language', 'en-US'),
                script_data.get('num_speakers', 2)
            )
        
        # åˆæˆæ‰€æœ‰æ®µè½
        segments_audio = []
        segments = script_data.get('segments', [])
        total_tts_chars = 0
        
        logger.info(f"æ­£åœ¨åˆæˆ {len(segments)} ä¸ªå¯¹è¯æ®µè½...\n")
        
        for idx, segment in enumerate(segments, 1):
            speaker_id = segment.get('speaker_id')
            speaker_name = segment.get('speaker_name')
            ssml_text = segment.get('ssml_text')
            
            if not ssml_text:
                logger.warning(f"[{idx}/{len(segments)}] âš ï¸  æ—  SSML æ–‡æœ¬: {speaker_name}")
                continue
            
            # è·å–å£°éŸ³é…ç½®
            voice_config = speaker_voice_map.get(speaker_id)
            if not voice_config:
                logger.warning(f"[{idx}/{len(segments)}] âš ï¸  æ— å£°éŸ³é…ç½®: {speaker_id}")
                continue
            
            logger.info(f"[{idx}/{len(segments)}] åˆæˆ {speaker_name} ({voice_config.voice_name})")
            
            try:
                # åˆæˆ - ç°åœ¨è¿”å› (audio_bytes, char_count)
                audio_bytes, char_count = self.synthesize_segment(ssml_text, voice_config)
                total_tts_chars += char_count
                audio = AudioSegment.from_mp3(io.BytesIO(audio_bytes))
                segments_audio.append(audio)
                
                duration_sec = len(audio) / 1000
                logger.info(f"              âœ… æˆåŠŸ ({duration_sec:.1f}s, {char_count}å­—ç¬¦)\n")
            
            except Exception as e:
                logger.error(f"              âŒ å¤±è´¥: {e}\n")
                raise
        
        if not segments_audio:
            raise ValueError("æ²¡æœ‰æˆåŠŸåˆæˆçš„éŸ³é¢‘æ®µè½")
        
        logger.info(f"âœ… æ‰€æœ‰æ®µè½åˆæˆå®Œæˆ\n")
        
        # åˆå¹¶æ‰€æœ‰æ®µè½
        logger.info("ğŸ“¦ åˆå¹¶éŸ³é¢‘æ®µè½...")
        merged = self._merge_segments(segments_audio)
        
        # å¯¼å‡º MP3
        output_file = self.output_dir / f"{podcast_name}.mp3"
        merged.export(str(output_file), format='mp3', bitrate='192k')
        
        # ç»Ÿè®¡ä¿¡æ¯
        duration_sec = len(merged) / 1000
        file_size_bytes = output_file.stat().st_size
        file_size_mb = file_size_bytes / (1024 * 1024)
        
        logger.info(f"âœ… æ’­å®¢ç”ŸæˆæˆåŠŸ!")
        logger.info(f"   è¾“å‡ºæ–‡ä»¶: {output_file.name}")
        logger.info(f"   æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
        logger.info(f"   å®é™…æ—¶é•¿: {int(duration_sec // 60)}åˆ†{int(duration_sec % 60)}ç§’")
        logger.info(f"   TTSå­—ç¬¦æ•°: {total_tts_chars}")
        logger.info("")
        
        return output_file, total_tts_chars, duration_sec, file_size_bytes
    
    def _merge_segments(self, segments: List[AudioSegment], pause_ms: int = 200) -> AudioSegment:
        """
        åˆå¹¶éŸ³é¢‘æ®µè½
        
        Args:
            segments: éŸ³é¢‘æ®µè½åˆ—è¡¨
            pause_ms: æ®µè½é—´åœé¡¿æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
        
        Returns:
            åˆå¹¶åçš„éŸ³é¢‘
        """
        if not segments:
            raise ValueError("æ²¡æœ‰éŸ³é¢‘æ®µè½å¯åˆå¹¶")
        
        silence = AudioSegment.silent(duration=pause_ms)
        
        merged = segments[0]
        for segment in segments[1:]:
            merged += silence
            merged += segment
        
        return merged
    
    def _get_default_voice_map(
        self,
        language_code: str = 'en-US',
        num_speakers: int = 2
    ) -> Dict[str, SpeakerVoiceConfig]:
        """
        è·å–é»˜è®¤å£°éŸ³æ˜ å°„
        
        Args:
            language_code: è¯­è¨€ä»£ç  (å¦‚ 'en-US', 'ko-KR', 'zh-CN')
            num_speakers: è®²è¯äººæ•°é‡
        
        Returns:
            è®²è¯äºº ID åˆ°å£°éŸ³é…ç½®çš„æ˜ å°„
        """
        
        voice_maps = {
            'en-US': {
                'speaker_1': SpeakerVoiceConfig(
                    speaker_id='speaker_1',
                    speaker_name='Speaker 1',
                    language_code='en-US',
                    voice_name='en-US-Neural2-I',  # ç”·æ€§
                    ssml_gender=texttospeech.SsmlVoiceGender.MALE,
                ),
                'speaker_2': SpeakerVoiceConfig(
                    speaker_id='speaker_2',
                    speaker_name='Speaker 2',
                    language_code='en-US',
                    voice_name='en-US-Neural2-F',  # å¥³æ€§
                    ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,
                ),
                'speaker_3': SpeakerVoiceConfig(
                    speaker_id='speaker_3',
                    speaker_name='Speaker 3',
                    language_code='en-US',
                    voice_name='en-US-Neural2-J',  # ç”·æ€§
                    ssml_gender=texttospeech.SsmlVoiceGender.MALE,
                ),
            },
            'ko-KR': {
                'speaker_1': SpeakerVoiceConfig(
                    speaker_id='speaker_1',
                    speaker_name='Speaker 1',
                    language_code='ko-KR',
                    voice_name='ko-KR-Neural2-A',  # ç”·æ€§
                    ssml_gender=texttospeech.SsmlVoiceGender.MALE,
                ),
                'speaker_2': SpeakerVoiceConfig(
                    speaker_id='speaker_2',
                    speaker_name='Speaker 2',
                    language_code='ko-KR',
                    voice_name='ko-KR-Neural2-B',  # å¥³æ€§
                    ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,
                ),
                'speaker_3': SpeakerVoiceConfig(
                    speaker_id='speaker_3',
                    speaker_name='Speaker 3',
                    language_code='ko-KR',
                    voice_name='ko-KR-Neural2-C',  # ç”·æ€§
                    ssml_gender=texttospeech.SsmlVoiceGender.MALE,
                ),
            },
            'zh-CN': {
                'speaker_1': SpeakerVoiceConfig(
                    speaker_id='speaker_1',
                    speaker_name='Speaker 1',
                    language_code='zh-CN',
                    voice_name='cmn-CN-Neural2-A',  # ç”·æ€§
                    ssml_gender=texttospeech.SsmlVoiceGender.MALE,
                ),
                'speaker_2': SpeakerVoiceConfig(
                    speaker_id='speaker_2',
                    speaker_name='Speaker 2',
                    language_code='zh-CN',
                    voice_name='cmn-CN-Neural2-B',  # å¥³æ€§
                    ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,
                ),
                'speaker_3': SpeakerVoiceConfig(
                    speaker_id='speaker_3',
                    speaker_name='Speaker 3',
                    language_code='zh-CN',
                    voice_name='cmn-CN-Neural2-D',  # ç”·æ€§
                    ssml_gender=texttospeech.SsmlVoiceGender.MALE,
                ),
            },
        }
        
        # è·å–è¯¥è¯­è¨€çš„æ˜ å°„ï¼Œæˆ–ä½¿ç”¨è‹±æ–‡ä½œä¸ºå¤‡é€‰
        voice_map_for_lang = voice_maps.get(language_code, voice_maps['en-US'])
        
        # è¿”å›éœ€è¦çš„è®²è¯äººæ•°é‡
        result = {}
        for i in range(1, num_speakers + 1):
            speaker_id = f'speaker_{i}'
            if speaker_id in voice_map_for_lang:
                result[speaker_id] = voice_map_for_lang[speaker_id]
        
        return result
